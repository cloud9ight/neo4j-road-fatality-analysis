{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "495084df",
   "metadata": {},
   "source": [
    "**Goal:**\n",
    " Generate clean CSVs for Nodes (Crash, Person, LGA, SA4, State) and Relationships (WAS_INVOLVED_IN, OCCURRED_IN, PART_OF, IN_STATE) that precisely match the headers needed for LOAD CSV and reflect graph model design in arrows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a74d389",
   "metadata": {},
   "source": [
    "## Cell 1: Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "259bf46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source file path: ../data/source/Project2_Dataset_Corrected.csv\n",
      "Output directory path: ../data/import_final\n",
      "Setup Complete. Necessary libraries imported and paths configured.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# --- Configuration ---\n",
    "SOURCE_FILE = os.path.join('..', 'data', 'source', 'Project2_Dataset_Corrected.csv')\n",
    "OUTPUT_DIR = os.path.join('..', 'data', 'import_final') # Output directory\n",
    "\n",
    "print(f\"Source file path: {SOURCE_FILE}\")\n",
    "print(f\"Output directory path: {OUTPUT_DIR}\")\n",
    "print(\"Setup Complete. Necessary libraries imported and paths configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd2d3b",
   "metadata": {},
   "source": [
    "## Cell 2: Load and Initial Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6371cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 10490 rows from ../data/source/Project2_Dataset_Corrected.csv\n",
      "--- Column Name Cleaning ---\n",
      "Original -> Cleaned:\n",
      "'ID' -> 'id'\n",
      "'Crash ID' -> 'crash_id'\n",
      "'State' -> 'state'\n",
      "'Month' -> 'month'\n",
      "'Year' -> 'year'\n",
      "'Dayweek' -> 'dayweek'\n",
      "'Time' -> 'time'\n",
      "'Crash Type' -> 'crash_type'\n",
      "'Number Fatalities' -> 'number_fatalities'\n",
      "'Bus Involvement' -> 'bus_involvement'\n",
      "'Heavy Rigid Truck Involvement' -> 'heavy_rigid_truck_involvement'\n",
      "'Articulated Truck Involvement' -> 'articulated_truck_involvement'\n",
      "'Speed Limit' -> 'speed_limit'\n",
      "'Road User' -> 'road_user'\n",
      "'Gender' -> 'gender'\n",
      "'Age' -> 'age'\n",
      "'National Remoteness Areas' -> 'national_remoteness_areas'\n",
      "'SA4 Name 2021' -> 'sa4_name_2021'\n",
      "'National LGA Name 2024' -> 'national_lga_name_2024'\n",
      "'National Road Type' -> 'national_road_type'\n",
      "'Christmas Period' -> 'christmas_period'\n",
      "'Easter Period' -> 'easter_period'\n",
      "'Age Group' -> 'age_group'\n",
      "'Day of week' -> 'day_of_week'\n",
      "'Time of day' -> 'time_of_day'\n",
      "\n",
      "--- DataFrame Info After Cleaning ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10490 entries, 0 to 10489\n",
      "Data columns (total 25 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   id                             10490 non-null  int64 \n",
      " 1   crash_id                       10490 non-null  int64 \n",
      " 2   state                          10490 non-null  object\n",
      " 3   month                          10490 non-null  int64 \n",
      " 4   year                           10490 non-null  int64 \n",
      " 5   dayweek                        10490 non-null  object\n",
      " 6   time                           10490 non-null  object\n",
      " 7   crash_type                     10490 non-null  object\n",
      " 8   number_fatalities              10490 non-null  int64 \n",
      " 9   bus_involvement                10490 non-null  object\n",
      " 10  heavy_rigid_truck_involvement  10490 non-null  object\n",
      " 11  articulated_truck_involvement  10490 non-null  object\n",
      " 12  speed_limit                    10490 non-null  int64 \n",
      " 13  road_user                      10490 non-null  object\n",
      " 14  gender                         10490 non-null  object\n",
      " 15  age                            10490 non-null  int64 \n",
      " 16  national_remoteness_areas      10490 non-null  object\n",
      " 17  sa4_name_2021                  10490 non-null  object\n",
      " 18  national_lga_name_2024         10490 non-null  object\n",
      " 19  national_road_type             10490 non-null  object\n",
      " 20  christmas_period               10490 non-null  object\n",
      " 21  easter_period                  10490 non-null  object\n",
      " 22  age_group                      10490 non-null  object\n",
      " 23  day_of_week                    10490 non-null  object\n",
      " 24  time_of_day                    10490 non-null  object\n",
      "dtypes: int64(7), object(18)\n",
      "memory usage: 2.0+ MB\n",
      "\n",
      "--- First 5 Rows After Cleaning ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>crash_id</th>\n",
       "      <th>state</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayweek</th>\n",
       "      <th>time</th>\n",
       "      <th>crash_type</th>\n",
       "      <th>number_fatalities</th>\n",
       "      <th>bus_involvement</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>national_remoteness_areas</th>\n",
       "      <th>sa4_name_2021</th>\n",
       "      <th>national_lga_name_2024</th>\n",
       "      <th>national_road_type</th>\n",
       "      <th>christmas_period</th>\n",
       "      <th>easter_period</th>\n",
       "      <th>age_group</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20241115</td>\n",
       "      <td>NSW</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>Friday</td>\n",
       "      <td>4:00</td>\n",
       "      <td>Single</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>Inner Regional Australia</td>\n",
       "      <td>Riverina</td>\n",
       "      <td>Wagga Wagga</td>\n",
       "      <td>Arterial Road</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>65_to_74</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20241125</td>\n",
       "      <td>NSW</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>Friday</td>\n",
       "      <td>6:15</td>\n",
       "      <td>Single</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>Inner Regional Australia</td>\n",
       "      <td>Sydney - Baulkham Hills and Hawkesbury</td>\n",
       "      <td>Hawkesbury</td>\n",
       "      <td>Local Road</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>17_to_25</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20246013</td>\n",
       "      <td>TAS</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>Friday</td>\n",
       "      <td>9:43</td>\n",
       "      <td>Single</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>Inner Regional Australia</td>\n",
       "      <td>Launceston and North East</td>\n",
       "      <td>Northern Midlands</td>\n",
       "      <td>Local Road</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>26_to_39</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20241002</td>\n",
       "      <td>NSW</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>Friday</td>\n",
       "      <td>10:35</td>\n",
       "      <td>Single</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>Outer Regional Australia</td>\n",
       "      <td>New England and North West</td>\n",
       "      <td>Armidale</td>\n",
       "      <td>National or State Highway</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>26_to_39</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20243185</td>\n",
       "      <td>QLD</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>Friday</td>\n",
       "      <td>13:00</td>\n",
       "      <td>Single</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>Inner Regional Australia</td>\n",
       "      <td>Toowoomba</td>\n",
       "      <td>Lockyer Valley</td>\n",
       "      <td>National or State Highway</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>40_to_64</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  crash_id state  month  year dayweek   time crash_type  \\\n",
       "0   1  20241115   NSW     12  2024  Friday   4:00     Single   \n",
       "1   2  20241125   NSW     12  2024  Friday   6:15     Single   \n",
       "2   3  20246013   TAS     12  2024  Friday   9:43     Single   \n",
       "3   4  20241002   NSW     12  2024  Friday  10:35     Single   \n",
       "4   5  20243185   QLD     12  2024  Friday  13:00     Single   \n",
       "\n",
       "   number_fatalities bus_involvement  ... age national_remoteness_areas  \\\n",
       "0                  1              No  ...  74  Inner Regional Australia   \n",
       "1                  1              No  ...  19  Inner Regional Australia   \n",
       "2                  1              No  ...  33  Inner Regional Australia   \n",
       "3                  1              No  ...  32  Outer Regional Australia   \n",
       "4                  1              No  ...  61  Inner Regional Australia   \n",
       "\n",
       "                            sa4_name_2021 national_lga_name_2024  \\\n",
       "0                                Riverina            Wagga Wagga   \n",
       "1  Sydney - Baulkham Hills and Hawkesbury             Hawkesbury   \n",
       "2               Launceston and North East      Northern Midlands   \n",
       "3              New England and North West               Armidale   \n",
       "4                               Toowoomba         Lockyer Valley   \n",
       "\n",
       "          national_road_type  christmas_period easter_period age_group  \\\n",
       "0              Arterial Road               Yes            No  65_to_74   \n",
       "1                 Local Road                No            No  17_to_25   \n",
       "2                 Local Road               Yes            No  26_to_39   \n",
       "3  National or State Highway                No            No  26_to_39   \n",
       "4  National or State Highway                No            No  40_to_64   \n",
       "\n",
       "  day_of_week time_of_day  \n",
       "0     Weekday       Night  \n",
       "1     Weekday         Day  \n",
       "2     Weekday         Day  \n",
       "3     Weekday         Day  \n",
       "4     Weekday         Day  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Load Raw Data ---\n",
    "try:\n",
    "    df_raw = pd.read_csv(SOURCE_FILE, low_memory=False)\n",
    "  \n",
    "    print(f\"Successfully loaded {len(df_raw)} rows from {SOURCE_FILE}\") \n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Source file not found at {SOURCE_FILE}. Please check the path.\")\n",
    "    # Stop execution if file not found\n",
    "    raise\n",
    "\n",
    "# --- Define Column Cleaning Function ---\n",
    "def clean_col_name(col_name):\n",
    "    col_name = str(col_name)\n",
    "    col_name = col_name.replace(' (', '_').replace(') ', '_').replace(' ', '_')\n",
    "    clean_name = re.sub(r'[^a-zA-Z0-9_]+', '', col_name).lower()\n",
    "    clean_name = clean_name.strip('_')\n",
    "    return clean_name\n",
    "\n",
    "# --- Apply Cleaning and Inspect ---\n",
    "df = df_raw.copy() # Work on a copy\n",
    "original_columns = df.columns.tolist()\n",
    "df.columns = [clean_col_name(col) for col in df.columns]\n",
    "cleaned_columns = df.columns.tolist()\n",
    "\n",
    "print(\"--- Column Name Cleaning ---\")\n",
    "print(\"Original -> Cleaned:\")\n",
    "for orig, clean in zip(original_columns, cleaned_columns):\n",
    "    if orig != clean:\n",
    "        print(f\"'{orig}' -> '{clean}'\")\n",
    "    else:\n",
    "        print(f\"'{orig}' -> (no change)\")\n",
    "\n",
    "print(\"\\n--- DataFrame Info After Cleaning ---\")\n",
    "df.info()\n",
    "print(\"\\n--- First 5 Rows After Cleaning ---\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff66916c",
   "metadata": {},
   "source": [
    "## Cell 3: Create Location Nodes AND Extract SA4-State Link Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625b4763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Location Node Files & Extracting Link Data---\n",
      "Saved 8 State nodes to ../data/import_final/states.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name:ID(State)</th>\n",
       "      <th>:LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NSW</td>\n",
       "      <td>State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TAS</td>\n",
       "      <td>State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QLD</td>\n",
       "      <td>State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SA</td>\n",
       "      <td>State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>VIC</td>\n",
       "      <td>State</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name:ID(State) :LABEL\n",
       "0             NSW  State\n",
       "2             TAS  State\n",
       "4             QLD  State\n",
       "5              SA  State\n",
       "73            VIC  State"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 88 SA4 nodes to ../data/import_final/sa4s.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name:ID(SA4)</th>\n",
       "      <th>:LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Riverina</td>\n",
       "      <td>SA4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sydney - Baulkham Hills and Hawkesbury</td>\n",
       "      <td>SA4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Launceston and North East</td>\n",
       "      <td>SA4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New England and North West</td>\n",
       "      <td>SA4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toowoomba</td>\n",
       "      <td>SA4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name:ID(SA4) :LABEL\n",
       "0                                Riverina    SA4\n",
       "1  Sydney - Baulkham Hills and Hawkesbury    SA4\n",
       "2               Launceston and North East    SA4\n",
       "3              New England and North West    SA4\n",
       "4                               Toowoomba    SA4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 509 LGA nodes to ../data/import_final/lgas.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name:ID(LGA)</th>\n",
       "      <th>:LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wagga Wagga</td>\n",
       "      <td>LGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hawkesbury</td>\n",
       "      <td>LGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Northern Midlands</td>\n",
       "      <td>LGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armidale</td>\n",
       "      <td>LGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lockyer Valley</td>\n",
       "      <td>LGA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name:ID(LGA) :LABEL\n",
       "0        Wagga Wagga    LGA\n",
       "1         Hawkesbury    LGA\n",
       "2  Northern Midlands    LGA\n",
       "3           Armidale    LGA\n",
       "4     Lockyer Valley    LGA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Location Node Files Created & SA4-State Link Data Extracted ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Creating Location Node Files & Extracting Link Data---\")\n",
    "\n",
    "# --- State nodes---\n",
    "states_nodes = df[['state']].drop_duplicates().dropna()\n",
    "states_nodes.rename(columns={'state': 'name:ID(State)'}, inplace=True)\n",
    "states_nodes[':LABEL'] = 'State'\n",
    "states_path = os.path.join(OUTPUT_DIR, 'states.csv')\n",
    "states_nodes.to_csv(states_path, index=False, encoding='utf-8')\n",
    "print(f\"Saved {len(states_nodes)} State nodes to {states_path}\")\n",
    "display(states_nodes.head()) \n",
    "\n",
    "# --- SA4 nodes & SA4-State Link Data  ---\n",
    "# for SA4-[:IN_STATE]->State relationship\n",
    "sa4_link_data = df[['sa4_name_2021', 'state']].drop_duplicates().dropna()\n",
    "# Generate unique SA4 nodes\n",
    "sa4_nodes = sa4_link_data[['sa4_name_2021']].drop_duplicates().copy()\n",
    "sa4_nodes.rename(columns={'sa4_name_2021': 'name:ID(SA4)'}, inplace=True)\n",
    "sa4_nodes[':LABEL'] = 'SA4'\n",
    "sa4s_path = os.path.join(OUTPUT_DIR, 'sa4s.csv')\n",
    "sa4_nodes.to_csv(sa4s_path, index=False, encoding='utf-8')\n",
    "print(f\"Saved {len(sa4_nodes)} SA4 nodes to {sa4s_path}\")\n",
    "display(sa4_nodes.head()) \n",
    "\n",
    "# --- LGAs Nodes ---\n",
    "lga_nodes = df[['national_lga_name_2024']].drop_duplicates().dropna().copy()\n",
    "lga_nodes.rename(columns={'national_lga_name_2024': 'name:ID(LGA)'}, inplace=True)\n",
    "lga_nodes[':LABEL'] = 'LGA'\n",
    "lgas_path = os.path.join(OUTPUT_DIR, 'lgas.csv')\n",
    "lga_nodes.to_csv(lgas_path, index=False, encoding='utf-8')\n",
    "print(f\"Saved {len(lga_nodes)} LGA nodes to {lgas_path}\")\n",
    "display(lga_nodes.head()) \n",
    "\n",
    "print(\"--- Location Node Files Created & SA4-State Link Data Extracted ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4513790",
   "metadata": {},
   "source": [
    "## Cell 4: Create Unique Crash Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fbc4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Unique Crash Node File & Crash Data for Relationships ---\n",
      "Saved 9683 unique Crash nodes to ../data/import_final/crashes.csv\n",
      "Created crash_id to internalCrashID map for Person->Crash linking.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_id</th>\n",
       "      <th>national_lga_name_2024</th>\n",
       "      <th>sa4_name_2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20241115</td>\n",
       "      <td>Wagga Wagga</td>\n",
       "      <td>Riverina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20241125</td>\n",
       "      <td>Hawkesbury</td>\n",
       "      <td>Sydney - Baulkham Hills and Hawkesbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20246013</td>\n",
       "      <td>Northern Midlands</td>\n",
       "      <td>Launceston and North East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20241002</td>\n",
       "      <td>Armidale</td>\n",
       "      <td>New England and North West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20243185</td>\n",
       "      <td>Lockyer Valley</td>\n",
       "      <td>Toowoomba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   crash_id national_lga_name_2024                           sa4_name_2021\n",
       "0  20241115            Wagga Wagga                                Riverina\n",
       "1  20241125             Hawkesbury  Sydney - Baulkham Hills and Hawkesbury\n",
       "2  20246013      Northern Midlands               Launceston and North East\n",
       "3  20241002               Armidale              New England and North West\n",
       "4  20243185         Lockyer Valley                               Toowoomba"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"--- Creating Unique Crash Node File & Crash Data for Relationships ---\")\n",
    "\n",
    "# Deduplicate based on 'crash_id'.\n",
    "# This crash_data DataFrame now holds one row per unique crash event\n",
    "# and retains all original columns (cleaned), including LGA and SA4 names needed for relationships.\n",
    "crash_data = df.drop_duplicates(subset=['crash_id'], keep='first').reset_index(drop=True).copy()\n",
    "\n",
    "# Generate Neo4j Internal ID for Crash nodes\n",
    "crash_data['internalCrashID:ID(Crash)'] = crash_data.index\n",
    "\n",
    "# Standardize Yes/No columns\n",
    "yes_no_cols = ['bus_involvement', 'heavy_rigid_truck_involvement',\n",
    "               'articulated_truck_involvement', 'christmas_period', 'easter_period']\n",
    "for col in yes_no_cols:\n",
    "    if col in crash_data.columns:\n",
    "        crash_data[col] = crash_data[col].astype(str).str.lower().map({'yes': 'yes', 'no': 'no'}).fillna('unknown')\n",
    "\n",
    "# Handle numeric types\n",
    "crash_data['year'] = pd.to_numeric(crash_data['year'], errors='coerce').fillna(0).astype(int)\n",
    "crash_data['month'] = pd.to_numeric(crash_data['month'], errors='coerce').fillna(0).astype(int)\n",
    "crash_data['number_fatalities'] = pd.to_numeric(crash_data['number_fatalities'], errors='coerce').fillna(0).astype(int)\n",
    "crash_data['speed_limit'] = pd.to_numeric(crash_data['speed_limit'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Define columns specifically for the Crash node properties CSV\n",
    "crash_node_properties_map = {\n",
    "    'internalCrashID:ID(Crash)': 'internalCrashID:ID(Crash)',\n",
    "    'crash_id': 'crashID_orig', # Store original crash_id as a property\n",
    "    'year': 'year', 'month': 'month', 'dayweek': 'dayweek', 'time': 'time',\n",
    "    'crash_type': 'crashType', 'number_fatalities': 'numberFatalities',\n",
    "    'bus_involvement': 'busInvolvement', 'heavy_rigid_truck_involvement': 'heavyRigidTruckInvolvement',\n",
    "    'articulated_truck_involvement': 'articulatedTruckInvolvement', 'speed_limit': 'speedLimit',\n",
    "    'national_road_type': 'nationalRoadType', 'christmas_period': 'christmasPeriod',\n",
    "    'easter_period': 'easterPeriod', 'national_remoteness_areas': 'nationalRemotenessAreas',\n",
    "    'day_of_week': 'dayOfWeekType', 'time_of_day': 'timeOfDay'\n",
    "    # LGA and SA4 names are in crash_data but not directly saved as properties on Crash node here,\n",
    "    # as they will be linked via relationships.\n",
    "}\n",
    "\n",
    "# Create the DataFrame for the crashes.csv node file\n",
    "crash_nodes_for_csv = crash_data[list(crash_node_properties_map.keys())].copy()\n",
    "crash_nodes_for_csv.rename(columns=crash_node_properties_map, inplace=True)\n",
    "crash_nodes_for_csv[':LABEL'] = 'Crash'\n",
    "\n",
    "crashes_path = os.path.join(OUTPUT_DIR, 'crashes.csv')\n",
    "crash_nodes_for_csv.to_csv(crashes_path, index=False, encoding='utf-8')\n",
    "print(f\"Saved {len(crash_nodes_for_csv)} unique Crash nodes to {crashes_path}\")\n",
    "\n",
    "# Create Mapping from original 'crash_id' (cleaned) to 'internalCrashID:ID(Crash)'\n",
    "# This is used for linking Person nodes to the correct internal Crash ID.\n",
    "# This map comes from crash_data which has both.\n",
    "crash_id_map = crash_data[['crash_id', 'internalCrashID:ID(Crash)']].copy().set_index('crash_id')\n",
    "print(\"Created crash_id to internalCrashID map for Person->Crash linking.\")\n",
    "display(crash_data[['crash_id', 'national_lga_name_2024', 'sa4_name_2021']].head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732656b2",
   "metadata": {},
   "source": [
    "## Cell 5: Create Person Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ee25f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Person Node File ---\n",
      "Saved 10490 Person nodes to ../data/import_final/persons.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personID:ID(Person)</th>\n",
       "      <th>roadUser</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>ageGroup</th>\n",
       "      <th>:LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Driver</td>\n",
       "      <td>Male</td>\n",
       "      <td>74</td>\n",
       "      <td>65_to_74</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Driver</td>\n",
       "      <td>Female</td>\n",
       "      <td>19</td>\n",
       "      <td>17_to_25</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Driver</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>26_to_39</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Driver</td>\n",
       "      <td>Female</td>\n",
       "      <td>32</td>\n",
       "      <td>26_to_39</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>Female</td>\n",
       "      <td>61</td>\n",
       "      <td>40_to_64</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   personID:ID(Person)   roadUser  gender  age  ageGroup  :LABEL\n",
       "0                    1     Driver    Male   74  65_to_74  Person\n",
       "1                    2     Driver  Female   19  17_to_25  Person\n",
       "2                    3     Driver  Female   33  26_to_39  Person\n",
       "3                    4     Driver  Female   32  26_to_39  Person\n",
       "4                    5  Passenger  Female   61  40_to_64  Person"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"--- Creating Person Node File ---\") # Replaced logging\n",
    "\n",
    "# --- Handle Data Types ---\n",
    "df['age'] = pd.to_numeric(df['age'], errors='coerce').fillna(-1).astype(int)\n",
    "\n",
    "# --- Select and Rename Columns for Neo4j ---\n",
    "person_node_cols = {\n",
    "    'id': 'personID:ID(Person)',\n",
    "    'road_user': 'roadUser', 'gender': 'gender', 'age': 'age', 'age_group': 'ageGroup'\n",
    "}\n",
    "person_nodes = df[list(person_node_cols.keys())].copy()\n",
    "person_nodes.rename(columns=person_node_cols, inplace=True)\n",
    "person_nodes[':LABEL'] = 'Person'\n",
    "\n",
    "# --- Save Person Nodes ---\n",
    "persons_path = os.path.join(OUTPUT_DIR, 'persons.csv')\n",
    "person_nodes.to_csv(persons_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Saved {len(person_nodes)} Person nodes to {persons_path}\") \n",
    "display(person_nodes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595e7236",
   "metadata": {},
   "source": [
    "## Cell 6: Create Relationship Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4cd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Relationship Files (Revised Model) ---\n",
      "Saved 88 :IN_STATE (SA4->State) relationships to ../data/import_final/rels_sa4_state.csv\n",
      "Saved 9683 :OCCURRED_IN_LGA (Crash->LGA) relationships to ../data/import_final/rels_crash_lga.csv\n",
      "Saved 9683 :OCCURRED_IN_SA4 (Crash->SA4) relationships to ../data/import_final/rels_crash_sa4.csv\n",
      "Saved 10490 :WAS_INVOLVED_IN (Person->Crash) relationships to ../data/import_final/rels_person_crash.csv\n",
      "\n",
      "--- All Relationship File Generation Complete (Revised Model) ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Creating Relationship Files ---\")\n",
    "\n",
    "# --- 1. SA4 -> State (:IN_STATE) ---\n",
    "# Uses sa4_link_data (SA4-State pairs) from Cell 3\n",
    "try:\n",
    "    sa4_state_rels = sa4_link_data.copy()\n",
    "    sa4_state_rels.rename(columns={'sa4_name_2021': ':START_ID(SA4)', 'state': ':END_ID(State)'}, inplace=True)\n",
    "    sa4_state_rels[':TYPE'] = 'IN_STATE'\n",
    "    rels_sa4_state_path = os.path.join(OUTPUT_DIR, 'rels_sa4_state.csv')\n",
    "    sa4_state_rels.to_csv(rels_sa4_state_path, index=False, encoding='utf-8')\n",
    "    print(f\"Saved {len(sa4_state_rels)} :IN_STATE (SA4->State) relationships to {rels_sa4_state_path}\")\n",
    "except Exception as e: print(f\"Error in :IN_STATE (SA4->State) relationships: {e}\")\n",
    "\n",
    "# --- 2. Crash -> LGA (:OCCURRED_IN_LGA) ---\n",
    "# Uses crash_data from Cell 4 (which has internalCrashID and national_lga_name_2024)\n",
    "try:\n",
    "    # Select necessary columns, drop rows if LGA name is missing\n",
    "    crash_lga_rels = crash_data[['internalCrashID:ID(Crash)', 'national_lga_name_2024']].dropna().copy()\n",
    "    crash_lga_rels.rename(columns={\n",
    "        'internalCrashID:ID(Crash)': ':START_ID(Crash)',\n",
    "        'national_lga_name_2024': ':END_ID(LGA)'\n",
    "    }, inplace=True)\n",
    "    crash_lga_rels[':TYPE'] = 'OCCURRED_IN_LGA'\n",
    "    rels_crash_lga_path = os.path.join(OUTPUT_DIR, 'rels_crash_lga.csv')\n",
    "    crash_lga_rels.to_csv(rels_crash_lga_path, index=False, encoding='utf-8')\n",
    "    print(f\"Saved {len(crash_lga_rels)} :OCCURRED_IN_LGA (Crash->LGA) relationships to {rels_crash_lga_path}\")\n",
    "except Exception as e: print(f\"Error in :OCCURRED_IN_LGA (Crash->LGA) relationships: {e}\")\n",
    "\n",
    "# --- 3. Crash -> SA4 (:OCCURRED_IN_SA4) --- NEW RELATIONSHIP\n",
    "# Uses crash_data from Cell 4 (which has internalCrashID and sa4_name_2021)\n",
    "try:\n",
    "    # Select necessary columns, drop rows if SA4 name is missing\n",
    "    crash_sa4_rels = crash_data[['internalCrashID:ID(Crash)', 'sa4_name_2021']].dropna().copy()\n",
    "    crash_sa4_rels.rename(columns={\n",
    "        'internalCrashID:ID(Crash)': ':START_ID(Crash)',\n",
    "        'sa4_name_2021': ':END_ID(SA4)'\n",
    "    }, inplace=True)\n",
    "    crash_sa4_rels[':TYPE'] = 'OCCURRED_IN_SA4'\n",
    "    rels_crash_sa4_path = os.path.join(OUTPUT_DIR, 'rels_crash_sa4.csv') # New CSV file\n",
    "    crash_sa4_rels.to_csv(rels_crash_sa4_path, index=False, encoding='utf-8')\n",
    "    print(f\"Saved {len(crash_sa4_rels)} :OCCURRED_IN_SA4 (Crash->SA4) relationships to {rels_crash_sa4_path}\")\n",
    "except Exception as e: print(f\"Error in :OCCURRED_IN_SA4 (Crash->SA4) relationships: {e}\")\n",
    "\n",
    "# --- 4. Person -> Crash (:WAS_INVOLVED_IN) ---\n",
    "# Uses original df (with cleaned 'id', 'crash_id') and crash_id_map (from Cell 4)\n",
    "try:\n",
    "    df_merged_person = df.merge(crash_id_map, left_on='crash_id', right_index=True, how='inner')\n",
    "    person_crash_rels = df_merged_person[['id', 'internalCrashID:ID(Crash)']].copy()\n",
    "    person_crash_rels.rename(columns={'id': ':START_ID(Person)', 'internalCrashID:ID(Crash)': ':END_ID(Crash)'}, inplace=True)\n",
    "    person_crash_rels[':TYPE'] = 'WAS_INVOLVED_IN'\n",
    "    rels_person_crash_path = os.path.join(OUTPUT_DIR, 'rels_person_crash.csv')\n",
    "    person_crash_rels.to_csv(rels_person_crash_path, index=False, encoding='utf-8')\n",
    "    print(f\"Saved {len(person_crash_rels)} :WAS_INVOLVED_IN (Person->Crash) relationships to {rels_person_crash_path}\")\n",
    "except Exception as e: print(f\"Error in :WAS_INVOLVED_IN (Person->Crash) relationships: {e}\")\n",
    "\n",
    "print(\"\\n--- All Relationship File Generation Complete ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
